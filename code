pip install numpy pandas nltk scikit-learn
import pandas as pd
from surprise import Dataset, Reader, SVD
from surprise.model_selection import train_test_split
from surprise import accuracy

# 1. Load ratings data
ratings = pd.read_csv("ratings_small.csv")   # columns: userId, movieId, rating, timestamp

# 2. Load keywords data
keywords = pd.read_csv("keywords.csv")       # columns: movieId, keywords

# 3. Prepare Surprise dataset
reader = Reader(rating_scale=(0.5, 5.0))
data = Dataset.load_from_df(ratings[["userId", "movieId", "rating"]], reader)

# 4. Train-test split
trainset, testset = train_test_split(data, test_size=0.2, random_state=42)

# 5. Train SVD model
algo = SVD(n_factors=50, n_epochs=20, random_state=42)
algo.fit(trainset)

# 6. Evaluate
predictions = algo.test(testset)
accuracy.rmse(predictions)

# 7. Recommend top-N movies for a user
def recommend_for_user(user_id, n=5):
    # Get all movie IDs
    all_movie_ids = ratings["movieId"].unique()
    # Movies already rated by this user
    rated = ratings.loc[ratings["userId"] == user_id, "movieId"].tolist()
    # Candidate movies
    candidates = [m for m in all_movie_ids if m not in rated]
    
    # Predict ratings
    scored = [(m, algo.predict(user_id, m).est) for m in candidates]
    scored = sorted(scored, key=lambda x: x[1], reverse=True)[:n]
    
    # Attach keywords for context
    recs = pd.DataFrame(scored, columns=["movieId", "predicted_rating"])
    recs = recs.merge(keywords, on="movieId", how="left")
    return recs

# Example: Recommend for user 1
print(recommend_for_user(user_id=1, n=5))



